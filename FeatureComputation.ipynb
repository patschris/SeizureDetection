{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyentrp import entropy\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import integrate, signal, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes  for the Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Left and Right Hemispheric Channel Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leftRightHemisphericChannels (df):\n",
    "    ndf = pd.DataFrame()\n",
    "    ndf['AvgLeftHemisphere'] = (df['F3-C3'] + df['C3-P3'])/2\n",
    "    ndf['AvgRightHemisphere'] = (df['F4-C4'] + df['C4-P4'])/2\n",
    "    ndf['seizure'] = df['seizure']\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Channel Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageChannels (df):\n",
    "    ndf = pd.DataFrame()\n",
    "    n = df.iloc[:, :df.shape[1]-1].copy()\n",
    "    ndf['surrogate'] = n.mean(axis=1)\n",
    "    ndf['seizure'] = df['seizure']\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://stackoverflow.com/questions/30272538/python-code-for-counting-number-of-zero-crossings-in-an-array\n",
    "https://stackoverflow.com/questions/5613244/root-mean-square-in-numpy-and-complications-of-matrix-and-arrays-of-numpy\n",
    "'''\n",
    "def computeTimeDomainFeatures (signal):\n",
    "    mean = np.mean(signal)\n",
    "    var = np.var(signal)\n",
    "    skew = stats.skew(signal)\n",
    "    kurt = stats.kurtosis(signal)\n",
    "    std = np.std(signal)\n",
    "    median = np.median(signal)\n",
    "    zcr = ((signal[:-1] * signal[1:]) < 0).sum()\n",
    "    if signal.mean() != 0: cv = stats.variation(signal)\n",
    "    else : cv = math.nan\n",
    "    if signal.size > 0: rms = np.sqrt(signal.dot(signal)/signal.size)\n",
    "    else: rms = math.nan\n",
    "    p2p = signal.max() - signal.min()\n",
    "    sampEn = entropy.sample_entropy(signal, 1)[0]\n",
    "    return mean, var, skew, kurt, std, median, zcr, cv, rms, p2p, sampEn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compute the average bandpower of an EEG signal\n",
    "https://raphaelvallat.com/bandpower.html\n",
    "'''\n",
    "def psd (x, fs, win):\n",
    "    bands = [0.5, 4, 8, 12, 30, 100]\n",
    "    freqs, psd = signal.welch(x, fs, nperseg = win)\n",
    "    avg_power=[]\n",
    "    while len(bands)>1:\n",
    "        idx = np.logical_and(freqs >= bands[0], freqs <= bands[1])\n",
    "        power_simps = integrate.simps(psd[idx], dx=bands[1]-bands[0])\n",
    "        avg_power.append(power_simps)\n",
    "        bands = np.copy(bands[1:])\n",
    "    for p in avg_power:\n",
    "        yield p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCorrelation (left, right):\n",
    "    return abs(np.correlate(left, right, 'full')).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractionLeftRight (df, sample_rate, step):\n",
    "    print('Feature Extraction')\n",
    "    ft = pd.DataFrame()\n",
    "    c = 0\n",
    "    for i in tqdm(range (0, df.shape[0], step)):\n",
    "        temp = df.iloc[i:i+step]\n",
    "        left = np.array(temp['AvgLeftHemisphere'])\n",
    "        right = np.array(temp['AvgRightHemisphere'])\n",
    "\n",
    "        # Time Domain Features\n",
    "        ft.loc[c,'Lmean'], ft.loc[c,'Lvar'], ft.loc[c,'Lskew'],ft.loc[c,'Lkurt'], ft.loc[c,'Lstd'], ft.loc[c,'Lmedian'], ft.loc[c,'Lzcr'], ft.loc[c,'Lcv'], ft.loc[c,'Lrms'], ft.loc[c,'Lp2p'],ft.loc[c,'LsampEn'] = computeTimeDomainFeatures(left)\n",
    "        ft.loc[c,'Rmean'], ft.loc[c,'Rvar'], ft.loc[c,'Rskew'],ft.loc[c,'Rkurt'], ft.loc[c,'Rstd'], ft.loc[c,'Rmedian'], ft.loc[c,'Rzcr'], ft.loc[c,'Rcv'], ft.loc[c,'Rrms'], ft.loc[c,'Rp2p'],ft.loc[c,'RsampEn'] = computeTimeDomainFeatures(right)\n",
    "\n",
    "        # Frequency Domain Features\n",
    "        ft.loc[c,'LdeltaPower'], ft.loc[c,'LthetaPower'], ft.loc[c,'LalphaPower'], ft.loc[c,'LbetaPower'], ft.loc[c,'LgammaPower'] = psd(left, sample_rate, left.shape[0])\n",
    "        ft.loc[c,'RdeltaPower'], ft.loc[c,'RthetaPower'], ft.loc[c,'RalphaPower'], ft.loc[c,'RbetaPower'], ft.loc[c,'RgammaPower'] = psd(right, sample_rate, right.shape[0])\n",
    "\n",
    "        \n",
    "        # Correlation Features\n",
    "        ft.loc[c, 'corr'] = computeCorrelation(left, right)\n",
    "\n",
    "        ft.loc[c, 'seizure'] = temp['seizure'].value_counts().idxmax()\n",
    "        c = c + 1\n",
    "    return ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractionAverage (df, sample_rate, step):\n",
    "    print('Feature Extraction')\n",
    "    ft = pd.DataFrame()\n",
    "    c = 0\n",
    "    for i in tqdm(range (0, df.shape[0], step)):\n",
    "        temp = df.iloc[i:i+step]\n",
    "        s = np.array(temp['surrogate'])\n",
    "        \n",
    "        # Time Domain Features\n",
    "        ft.loc[c,'mean'], ft.loc[c,'var'], ft.loc[c,'skew'],ft.loc[c,'kurt'], ft.loc[c,'std'], ft.loc[c,'median'], ft.loc[c,'zcr'], ft.loc[c,'cv'], ft.loc[c,'rms'], ft.loc[c,'p2p'],ft.loc[c,'sampEn'] = computeTimeDomainFeatures(s)\n",
    "       \n",
    "        # Frequency Domain Features\n",
    "        ft.loc[c,'deltaPower'], ft.loc[c,'thetaPower'], ft.loc[c,'alphaPower'], ft.loc[c,'betaPower'], ft.loc[c,'gammaPower'] = psd(s, sample_rate, s.shape[0])\n",
    "        \n",
    "        ft.loc[c, 'seizure'] = temp['seizure'].value_counts().idxmax()\n",
    "        c = c + 1\n",
    "    return ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractionFull (df, sample_rate, step):\n",
    "    print('Feature Extraction')\n",
    "    ft = pd.DataFrame()\n",
    "    c = 0\n",
    "    for i in tqdm(range (0, df.shape[0], step)):\n",
    "        temp = df.iloc[i:i+step]\n",
    "        for j in range(0, df.shape[1]-1):\n",
    "            s = np.array(temp.iloc[:, j])\n",
    "\n",
    "            # Time Domain Features\n",
    "            ft.loc[c, 'mean'+str(j)], ft.loc[c, 'var'+str(j)], ft.loc[c, 'skew'+str(j)],ft.loc[c, 'kurt'+str(j)], ft.loc[c, 'std'+str(j)], ft.loc[c, 'median'+str(j)], ft.loc[c, 'zcr'+str(j)], ft.loc[c, 'cv'+str(j)], ft.loc[c, 'rms'+str(j)], ft.loc[c, 'p2p'+str(j)],ft.loc[c, 'sampEn'+str(j)] = computeTimeDomainFeatures(s)\n",
    "\n",
    "            # Frequency Domain Features\n",
    "            ft.loc[c, 'deltaPower'+str(j)], ft.loc[c, 'thetaPower'+str(j)], ft.loc[c, 'alphaPower'+str(j)], ft.loc[c, 'betaPower'+str(j)], ft.loc[c, 'gammaPower'+str(j)] = psd(s, sample_rate, s.shape[0])\n",
    "\n",
    "        ft.loc[c, 'seizure'] = temp['seizure'].value_counts().idxmax()\n",
    "        c = c + 1\n",
    "    return ft"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

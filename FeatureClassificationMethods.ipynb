{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.ClassificationPerformanceIndexes import classificationPerformanceIndexes, printClassificationPerformanceIndexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(X_train, y_train, X_test, y_test, results):\n",
    "    print('Implementing SVM method...')\n",
    "    start = time.time()\n",
    "    clf = SVC(C = 1.0, kernel = 'rbf', gamma = 100)\n",
    "    svm_ind = clf.fit(X_train, y_train).predict(X_test)\n",
    "    end = time.time()\n",
    "    t = round(end - start,2)\n",
    "    acc, snv, spc, ppv, f1, mcc, kappa, tt = classificationPerformanceIndexes (y_test, svm_ind, t)\n",
    "    results.loc['SVM', :] = acc, snv, spc, ppv, f1, mcc, kappa, t\n",
    "    printClassificationPerformanceIndexes('KNN', acc, snv, spc, ppv, f1, mcc, kappa)\n",
    "    print('SVM finished in', t, 'sec\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_Kfold(X, kf, cols, results):\n",
    "    f = pd.DataFrame(columns = cols)\n",
    "    print('Implementing SVM k-fold...')\n",
    "    start = time.time()\n",
    "    clf = SVC(C = 1.0, kernel = 'rbf', gamma = 100)\n",
    "    for train, test in kf.split(X):\n",
    "        X_train = X.iloc[train,:X.shape[1]-1]\n",
    "        y_train = X.loc[train,'seizure']\n",
    "        X_test = X.iloc[test,:X.shape[1]-1]\n",
    "        y_test = X.loc[test,'seizure']\n",
    "        svm_ind = clf.fit(X_train, y_train).predict(X_test)\n",
    "        f.loc[f.shape[0], :] = classificationPerformanceIndexes (y_test, svm_ind, 0)\n",
    "    end = time.time()\n",
    "    t = round(end - start,2)    \n",
    "    acc, snv, spc, ppv, f1, mcc, kappa, tt = np.array(f.mean(axis=0))\n",
    "    results.loc['SVM Kfold', :] = acc, snv, spc, ppv, f1, mcc, kappa, t\n",
    "    printClassificationPerformanceIndexes('KNN Kfold', acc, snv, spc, ppv, f1, mcc, kappa)\n",
    "    print('SVM k-fold finished in', t, 'sec\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompleteSVM(train_dat, test_dat, train_ind, test_ind, results, features, kf, perfInd):\n",
    "    SVM(train_dat, train_ind, test_dat, test_ind, results)\n",
    "    SVM_Kfold(features, kf, perfInd, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(X_train, y_train, X_test, y_test, experiment,results):\n",
    "    print('Implementing KNN...')\n",
    "    start = time.time()\n",
    "    clf = KNeighborsClassifier(n_neighbors = 3, weights='distance', metric = 'manhattan', n_jobs = -1)\n",
    "    knn_ind = clf.fit(X_train, y_train).predict(X_test)\n",
    "    end = time.time()\n",
    "    t = round(end - start,2)    \n",
    "    acc, snv, spc, ppv, f1, mcc, kappa, tt = classificationPerformanceIndexes (y_test, knn_ind, t)\n",
    "    results.loc['KNN', :] = acc, snv, spc, ppv, f1, mcc, kappa, t\n",
    "    printClassificationPerformanceIndexes('KNN', acc, snv, spc, ppv, f1, mcc, kappa)\n",
    "    print('KNN finished in', t,'sec\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_Kfold(X, experiment, kf, cols, results):\n",
    "    f = pd.DataFrame(columns = cols)\n",
    "    print('Implementing KNN k-fold...')\n",
    "    start = time.time()\n",
    "    clf = KNeighborsClassifier(n_neighbors = 3, weights='distance', metric = 'manhattan', n_jobs = -1)\n",
    "    for train, test in kf.split(X):\n",
    "        X_train = X.iloc[train,:X.shape[1]-1]\n",
    "        y_train = X.loc[train,'seizure']\n",
    "        X_test = X.iloc[test,:X.shape[1]-1]\n",
    "        y_test = X.loc[test,'seizure']\n",
    "        knn_ind = clf.fit(X_train, y_train).predict(X_test)\n",
    "        f.loc[f.shape[0], :] = classificationPerformanceIndexes (y_test, knn_ind, 0)\n",
    "    end = time.time()\n",
    "    t = round(end - start,2)    \n",
    "    acc, snv, spc, ppv, f1, mcc, kappa, tt =  np.array(f.mean(axis=0))\n",
    "    printClassificationPerformanceIndexes('KNN Kfold', acc, snv, spc, ppv, f1, mcc, kappa)\n",
    "    results.loc['KNN Kfold', :] = acc, snv, spc, ppv, f1, mcc, kappa, t\n",
    "    print('KNN k-fold finished in', t,'sec\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompleteKNN(train_dat, test_dat, train_ind, test_ind, results, experiment, features, kf, perfInd):\n",
    "    KNN(train_dat, train_ind, test_dat, test_ind, experiment, results)\n",
    "    KNN_Kfold(features, experiment, kf, perfInd, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayes(X_train, y_train, X_test, y_test, results):\n",
    "    print('Implementing Naive Bayes...')\n",
    "    start = time.time()\n",
    "    clf = GaussianNB()\n",
    "    nb_ind = clf.fit(X_train, y_train).predict(X_test)\n",
    "    end = time.time()\n",
    "    t = round(end - start,2)\n",
    "    acc, snv, spc, ppv, f1, mcc, kappa, tt = classificationPerformanceIndexes (y_test, nb_ind, t)\n",
    "    results.loc['Naive Bayes', :] = acc, snv, spc, ppv, f1, mcc, kappa, t\n",
    "    printClassificationPerformanceIndexes('Naive Bayes', acc, snv, spc, ppv, f1, mcc, kappa)\n",
    "    print('Naive Bayes finished in', t,'sec\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayes_Kfold(X, kf, cols, results):\n",
    "    f = pd.DataFrame(columns = cols)\n",
    "    print('Implementing Naive Bayes k-fold...')\n",
    "    start = time.time()\n",
    "    clf = GaussianNB()\n",
    "    for train, test in kf.split(X):\n",
    "        X_train = X.iloc[train,:X.shape[1]-1]\n",
    "        y_train = X.loc[train,'seizure']\n",
    "        X_test = X.iloc[test,:X.shape[1]-1]\n",
    "        y_test = X.loc[test,'seizure']\n",
    "        nb_ind = clf.fit(X_train, y_train).predict(X_test)\n",
    "        f.loc[f.shape[0], :] = classificationPerformanceIndexes (y_test, nb_ind, 0)\n",
    "    end = time.time()\n",
    "    t = round(end - start,2)        \n",
    "    acc, snv, spc, ppv, f1, mcc, kappa, tt = np.array(f.mean(axis=0))\n",
    "    results.loc['Naive Bayes Kfold', :] = acc, snv, spc, ppv, f1, mcc, kappa, t\n",
    "    printClassificationPerformanceIndexes('Naive Bayes k-fold', acc, snv, spc, ppv, f1, mcc, kappa)\n",
    "    print('Naive Bayes k_fold finished in', t,'sec\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompleteNB(train_dat, test_dat, train_ind, test_ind, results, features, kf, perfInd):\n",
    "    NaiveBayes(train_dat, train_ind, test_dat, test_ind, results)\n",
    "    NaiveBayes_Kfold(features, kf, perfInd, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTrees(X_train, y_train, X_test, y_test, experiment, results):\n",
    "    clf = DecisionTreeClassifier()\n",
    "    print('Implementing Decision Trees...')\n",
    "    start = time.time()\n",
    "    if experiment.upper() == 'AVERAGE': c, md, mss = 'gini', 62, 2\n",
    "    elif experiment.upper() == 'LEFTRIGHT': c, md, mss = 'entropy', 82, 2\n",
    "    else: c, md, mss = 'entropy', 42, 12\n",
    "    clf = DecisionTreeClassifier(criterion = c, max_depth = md, min_samples_split = mss, splitter = 'best')\n",
    "    dt_ind = clf.fit(X_train, y_train).predict(X_test)\n",
    "    end = time.time()\n",
    "    t = round(end - start,2)\n",
    "    acc, snv, spc, ppv, f1, mcc, kappa, tt = classificationPerformanceIndexes (y_test, dt_ind, t)\n",
    "    results.loc['Decision Trees', :] = acc, snv, spc, ppv, f1, mcc, kappa, t\n",
    "    printClassificationPerformanceIndexes('Decision Trees', acc, snv, spc, ppv, f1, mcc, kappa)\n",
    "    print('Decision Trees finished in', t,'sec\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTrees_Kfold(X, kf, cols, experiment, results):\n",
    "    f = pd.DataFrame(columns = cols)\n",
    "    print('Implementing Decision Trees k-fold...')\n",
    "    start = time.time()\n",
    "    if experiment.upper() == 'AVERAGE': c, md, mss = 'gini', 62, 2\n",
    "    elif experiment.upper() == 'LEFTRIGHT': c, md, mss = 'entropy', 82, 2\n",
    "    else: c, md, mss = 'entropy', 42, 12\n",
    "    clf = DecisionTreeClassifier(criterion = c, max_depth = md, min_samples_split = mss, splitter = 'best')\n",
    "    for train, test in kf.split(X):\n",
    "        X_train = X.iloc[train,:X.shape[1]-1]\n",
    "        y_train = X.loc[train,'seizure']\n",
    "        X_test = X.iloc[test,:X.shape[1]-1]\n",
    "        y_test = X.loc[test,'seizure']\n",
    "        dt_ind = clf.fit(X_train, y_train).predict(X_test)\n",
    "        f.loc[f.shape[0], :] = classificationPerformanceIndexes (y_test, dt_ind, 0)\n",
    "    end = time.time()\n",
    "    t = round(end - start,2)\n",
    "    acc, snv, spc, ppv, f1, mcc, kappa, tt = np.array(f.mean(axis=0))\n",
    "    results.loc['Decision Trees Kfold', :] = acc, snv, spc, ppv, f1, mcc, kappa, t    \n",
    "    printClassificationPerformanceIndexes('Decision Trees Kfold', acc, snv, spc, ppv, f1, mcc, kappa)\n",
    "    print('Decision Trees k-fold finished in', t,'sec\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompleteDT(train_dat, test_dat, train_ind, test_ind, results, features, kf, experiment, perfInd):\n",
    "    DecisionTrees(train_dat, train_ind, test_dat, test_ind, experiment, results)\n",
    "    DecisionTrees_Kfold(features, kf, perfInd, experiment, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(X_train, y_train, X_test, y_test, experiment, results):\n",
    "    print('Implementing Random Forest...')\n",
    "    start = time.time()\n",
    "    if experiment.upper() == 'AVERAGE': c, md, mss,est = 'gini', 62, 2, 10\n",
    "    elif experiment.upper() == 'LEFTRIGHT': c, md, mss, est = 'gini', 82, 2, 70\n",
    "    else: c, md, mss, est = 'entropy', 42, 2, 50\n",
    "    clf = RandomForestClassifier(n_estimators = est, criterion = c, max_depth = md, min_samples_split = mss, n_jobs = -1)\n",
    "    rf_ind = clf.fit(X_train, y_train).predict(X_test)\n",
    "    end = time.time()\n",
    "    t = round(end - start,2)\n",
    "    acc, snv, spc, ppv, f1, mcc, kappa, tt = classificationPerformanceIndexes (y_test, rf_ind, t)\n",
    "    results.loc['Random Forest', :] = acc, snv, spc, ppv, f1, mcc, kappa, t\n",
    "    printClassificationPerformanceIndexes('Random Forest', acc, snv, spc, ppv, f1, mcc, kappa)\n",
    "    print('Random Forest finished in', t,'sec\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest_Kfold(X, experiment, kf, cols, results):\n",
    "    f = pd.DataFrame(columns = cols)\n",
    "    print('Implementing Random Forest k-fold...')\n",
    "    start = time.time()\n",
    "    if experiment.upper() == 'AVERAGE': c, md, mss,est = 'gini', 62, 2, 10\n",
    "    elif experiment.upper() == 'LEFTRIGHT': c, md, mss, est = 'gini', 82, 2, 70\n",
    "    else: c, md, mss, est = 'entropy', 42, 2, 50\n",
    "    clf = RandomForestClassifier(n_estimators = est, criterion = c, max_depth = md, min_samples_split = mss, n_jobs = -1)\n",
    "    for train, test in kf.split(X):\n",
    "        X_train = X.iloc[train,:X.shape[1]-1]\n",
    "        y_train = X.loc[train,'seizure']\n",
    "        X_test = X.iloc[test,:X.shape[1]-1]\n",
    "        y_test = X.loc[test,'seizure']\n",
    "        rf_ind = clf.fit(X_train, y_train).predict(X_test)\n",
    "        f.loc[f.shape[0], :] = classificationPerformanceIndexes (y_test, rf_ind, 0)\n",
    "    end = time.time()\n",
    "    t = round(end - start,2)\n",
    "    acc, snv, spc, ppv, f1, mcc, kappa, tt = np.array(f.mean(axis=0))\n",
    "    results.loc['Random Forest Kfold', :] = acc, snv, spc, ppv, f1, mcc, kappa, t\n",
    "    printClassificationPerformanceIndexes('Random Forest Kfold', acc, snv, spc, ppv, f1, mcc, kappa)\n",
    "    print('Random Forest k-fold finished in', t,'sec\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompleteRF(train_dat, test_dat, train_ind, test_ind, results, rf_estimators, features, kf, perfInd):\n",
    "    RandomForest(train_dat, train_ind, test_dat, test_ind, rf_estimators, results)\n",
    "    RandomForest_Kfold(features, rf_estimators, kf, perfInd, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA(X_train, y_train, X_test, y_test, experiment, results):\n",
    "    print('Implementing LDA...')\n",
    "    start = time.time()\n",
    "    shr = 0\n",
    "    if experiment.upper() == 'LEFTRIGHT': shr = 'auto'\n",
    "    clf = LinearDiscriminantAnalysis(solver = 'lsqr', shrinkage = shr, tol = 1e-4)\n",
    "    lda_ind = clf.fit(X_train, y_train).predict(X_test)\n",
    "    end = time.time()\n",
    "    t = round(end - start,2)\n",
    "    acc, snv, spc, ppv, f1, mcc, kappa, tt = classificationPerformanceIndexes (y_test, lda_ind, t)\n",
    "    results.loc['LDA', :] = acc, snv, spc, ppv, f1, mcc, kappa, t\n",
    "    printClassificationPerformanceIndexes('LDA', acc, snv, spc, ppv, f1, mcc, kappa)\n",
    "    print('LDA finished in', t,'sec\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA_Kfold(X, kf, experiment,cols, results):\n",
    "    f = pd.DataFrame(columns = cols)\n",
    "    print('Implementing LDA k-fold...')\n",
    "    start = time.time()\n",
    "    shr = 0\n",
    "    if experiment.upper() == 'LEFTRIGHT': shr = 'auto'\n",
    "    clf = LinearDiscriminantAnalysis(solver = 'lsqr', shrinkage = shr, tol = 1e-4)\n",
    "    for train, test in kf.split(X):\n",
    "        X_train = X.iloc[train,:X.shape[1]-1]\n",
    "        y_train = X.loc[train,'seizure']\n",
    "        X_test = X.iloc[test,:X.shape[1]-1]\n",
    "        y_test = X.loc[test,'seizure']\n",
    "        lda_ind = clf.fit(X_train, y_train).predict(X_test)\n",
    "        f.loc[f.shape[0], :] = classificationPerformanceIndexes (y_test, lda_ind, 0)\n",
    "    end = time.time()\n",
    "    t = round(end - start,2)\n",
    "    acc, snv, spc, ppv, f1, mcc, kappa, tt = np.array(f.mean(axis=0))\n",
    "    results.loc['LDA Kfold', :] = acc, snv, spc, ppv, f1, mcc, kappa, t\n",
    "    printClassificationPerformanceIndexes('LDA Kfold', acc, snv, spc, ppv, f1, mcc, kappa)\n",
    "    print('LDA k-fold finished in', t,'sec\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompleteLDA(train_dat, test_dat, train_ind, test_ind, results, experiment, features, kf, perfInd):\n",
    "    LDA(train_dat, train_ind, test_dat, test_ind, experiment, results)\n",
    "    LDA_Kfold(features, kf, experiment, perfInd, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogReg(X_train, y_train, X_test, y_test, results, experiment):\n",
    "    print('Implementing Logistic Regression...')\n",
    "    start = time.time()\n",
    "    if experiment.upper() == 'AVERAGE': it = 500\n",
    "    elif experiment.upper() == 'LEFTRIGHT': it = 100\n",
    "    else: it = 1000\n",
    "    clf = LogisticRegression(penalty = 'l1', C = 0.01, max_iter = it, solver = 'liblinear')\n",
    "    lr_ind = clf.fit(X_train, y_train).predict(X_test)\n",
    "    end = time.time()\n",
    "    t = round(end - start,2)    \n",
    "    acc, snv, spc, ppv, f1, mcc, kappa, tt = classificationPerformanceIndexes (y_test, lr_ind, t)\n",
    "    results.loc['Logistic Regression', :] = acc, snv, spc, ppv, f1, mcc, kappa, t\n",
    "    printClassificationPerformanceIndexes('Logistic Regression', acc, snv, spc, ppv, f1, mcc, kappa)\n",
    "    print('Logistic Regression finished in', t,'sec\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogReg_Kfold(X, kf, cols, results, experiment):\n",
    "    f = pd.DataFrame(columns = cols)\n",
    "    print('Implementing Logistic Regression k-fold...')\n",
    "    start = time.time()\n",
    "    if experiment.upper() == 'AVERAGE': it = 500\n",
    "    elif experiment.upper() == 'LEFTRIGHT': it = 100\n",
    "    else: it = 1000\n",
    "    clf = LogisticRegression(penalty = 'l1', C = 0.01, max_iter = it, solver = 'liblinear')\n",
    "    for train, test in kf.split(X):\n",
    "        X_train = X.iloc[train,:X.shape[1]-1]\n",
    "        y_train = X.loc[train,'seizure']\n",
    "        X_test = X.iloc[test,:X.shape[1]-1]\n",
    "        y_test = X.loc[test,'seizure']\n",
    "        lr_ind = clf.fit(X_train, y_train).predict(X_test)\n",
    "        f.loc[f.shape[0], :] = classificationPerformanceIndexes (y_test, lr_ind, 0)\n",
    "    end = time.time()\n",
    "    t = round(end - start,2)\n",
    "    acc, snv, spc, ppv, f1, mcc, kappa, tt = np.array(f.mean(axis=0))\n",
    "    results.loc['Logistic Regression Kfold', :] = acc, snv, spc, ppv, f1, mcc, kappa, t\n",
    "    printClassificationPerformanceIndexes('Logistic Regression Kfold', acc, snv, spc, ppv, f1, mcc, kappa)\n",
    "    print('Logistic Regression k-fold finished in', t,'sec\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompleteLR(train_dat, test_dat, train_ind, test_ind, results, experiment, features, kf, perfInd):\n",
    "    LogReg(train_dat, train_ind, test_dat, test_ind, results, experiment)\n",
    "    LogReg_Kfold(features, kf, perfInd, results, experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LstmModel (size, lstm_units, dense_units, dropout_percentage, loss_function, metric):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_units, recurrent_regularizer = l2(1e-2), activity_regularizer = l2(1e-4), bias_regularizer = l2(1e-6)))\n",
    "    model.add(Dropout(dropout_percentage))\n",
    "    model.add(Dense(dense_units, activation = 'relu', kernel_regularizer = l2(1e-3), bias_regularizer = l2(1e-2)))\n",
    "    model.add(Dropout(dropout_percentage/2))\n",
    "    model.add(Dense(1, activation = 'sigmoid', kernel_regularizer = l2(1e-3), bias_regularizer = l2(1e-2)))\n",
    "    model.compile(optimizer = Adam(learning_rate = 1e-3), loss = loss_function, metrics = metric)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_method (model, X_train, y_train, X_test, y_test, batch, epochs, results):\n",
    "    print('Implementing LSTM...')\n",
    "    start = time.time()\n",
    "    es = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5, mode = 'auto', restore_best_weights = True, verbose = 0)\n",
    "    history = model.fit(X_train, y_train, batch_size = batch, epochs = epochs, validation_data = (X_test,y_test), callbacks = es, verbose = 0)\n",
    "    lstm_ind = (model.predict(X_test, batch_size = batch) >= 0.5).astype('int')\n",
    "    end = time.time()\n",
    "    t = round(end - start,2)\n",
    "    acc, snv, spc, ppv, f1, mcc, kappa, tt = classificationPerformanceIndexes (y_test, np.reshape(lstm_ind, lstm_ind.shape[0]), t)\n",
    "    results.loc['LSTM', :] = acc, snv, spc, ppv, f1, mcc, kappa, t\n",
    "    printClassificationPerformanceIndexes('LSTM', acc, snv, spc, ppv, f1, mcc, kappa)\n",
    "    print('LSTM finished in', t,'sec\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_method_Kfold(X, kf, cols, model, batch, epochs, results):\n",
    "    f = pd.DataFrame(columns = cols)\n",
    "    print('Implementing LSTM k-fold...')\n",
    "    start = time.time()\n",
    "    es = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5, mode = 'auto', restore_best_weights = True, verbose = 0)\n",
    "    for train, test in kf.split(X):\n",
    "        X_train = X.iloc[train,:X.shape[1]-1]\n",
    "        X_train = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "        y_train = X.loc[train,'seizure'].values.astype(int)\n",
    "        X_test = X.iloc[test,:X.shape[1]-1]\n",
    "        X_test = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "        y_test = X.loc[test,'seizure'].values.astype(int)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch, epochs = epochs, validation_data = (X_test,y_test), callbacks = es, verbose = 0)\n",
    "        lstm_ind = (model.predict(X_test, batch_size = batch) >= 0.5).astype('int')\n",
    "        f.loc[f.shape[0], :] = classificationPerformanceIndexes (y_test, np.reshape(lstm_ind, lstm_ind.shape[0]), 0)\n",
    "    end = time.time()\n",
    "    t = round(end - start,2)\n",
    "    acc, snv, spc, ppv, f1, mcc, kappa, tt = np.array(f.mean(axis=0))\n",
    "    results.loc['LSTM Kfold', :] = acc, snv, spc, ppv, f1, mcc, kappa, t\n",
    "    printClassificationPerformanceIndexes('LSTM Kfold', acc, snv, spc, ppv, f1, mcc, kappa)\n",
    "    print('LSTM finished in', t,'sec\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompleteLSTM (train_dat, test_dat, train_ind, test_ind, results, ft, kf, perfInd, epochs, batch, lstm_units, dense_units, dropout_percentage, loss_function, metric):\n",
    "    X_train = np.reshape(train_dat.values, (train_dat.shape[0], 1, train_dat.shape[1]))\n",
    "    y_train = train_ind.values.astype(int)\n",
    "    X_test = np.reshape(test_dat.values, (test_dat.shape[0], 1, test_dat.shape[1]))\n",
    "    y_test = test_ind.values.astype(int)\n",
    "\n",
    "    lstm_model = LstmModel (train_dat.shape[1], lstm_units, dense_units, dropout_percentage, loss_function, metric)\n",
    "    LSTM_method (lstm_model, X_train, y_train, X_test, y_test, batch, epochs, results)\n",
    "    LSTM_method_Kfold (ft, kf, perfInd, lstm_model, batch, epochs, results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.EdfManipulation import read_and_store_data\n",
    "from ipynb.fs.full.FeatureSelection import dimentionalityReduction\n",
    "from ipynb.fs.full.SplitDataset import createTrainingAndTestDatasets\n",
    "from ipynb.fs.full.DatasetBalancing import minorityOversampling, majorityUndersampling\n",
    "from ipynb.fs.full.FeatureNormalization import featureNormalization, removeNonNumericValues\n",
    "from ipynb.fs.full.ClassificationPerformanceIndexes import classificationPerformanceIndexes, printClassificationPerformanceIndexes\n",
    "from ipynb.fs.full.FeatureClassificationMethods import CompleteSVM, CompleteKNN, CompleteNB, CompleteDT, CompleteRF, CompleteLDA, CompleteLR, CompleteLSTM\n",
    "from ipynb.fs.full.FeatureComputation import leftRightHemisphericChannels, featureExtractionLeftRight, averageChannels, featureExtractionAverage, featureExtractionFull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtraction (df, sample_rate, step, pca_tolerance, undersampling_method, undersampling_rate, undersampling_neighbors, oversampling_method, oversampling_neighbors, experiment):\n",
    "    if experiment.upper() == 'FULL':\n",
    "        ft = pd.DataFrame(featureExtractionFull (df, sample_rate, step))\n",
    "    elif experiment.upper() == 'AVERAGE':\n",
    "        ft = pd.DataFrame(featureExtractionAverage (averageChannels(df), sample_rate, step))\n",
    "    else:\n",
    "        ft = pd.DataFrame(featureExtractionLeftRight (leftRightHemisphericChannels(df), sample_rate, step))\n",
    "    removeNonNumericValues(ft)\n",
    "    ft = featureNormalization(ft)\n",
    "    print('Normalized features')\n",
    "    removeNonNumericValues(ft)\n",
    "    size = ft.shape\n",
    "    print('Reducing features dimension')\n",
    "    ft = dimentionalityReduction(ft, pca_tolerance)\n",
    "    removeNonNumericValues(ft)\n",
    "    print('Dimensions reduced from', size, 'to', ft.shape)\n",
    "    size = ft.seizure.value_counts()\n",
    "    print('Undersampling the majority class using', undersampling_method)\n",
    "    ft = majorityUndersampling(ft.loc[:, ft.columns != 'seizure'], ft['seizure'], undersampling_rate, undersampling_neighbors, undersampling_method)\n",
    "    removeNonNumericValues(ft)\n",
    "    print('Majority class downsampled from (', size[0], ', ', ft.shape[1], ') to ', ft.shape, sep = '')\n",
    "    size = ft.shape\n",
    "    print('Oversampling the minority class using', oversampling_method)\n",
    "    ft = minorityOversampling(ft.loc[:, ft.columns != 'seizure'], ft['seizure'], oversampling_neighbors, oversampling_method)\n",
    "    ft = shuffle(ft)\n",
    "    ft.reset_index(drop = True, inplace = True)\n",
    "    removeNonNumericValues(ft)\n",
    "    print('Minority class upsampled from (', size[0], ', ', ft.shape[1], ') to ', ft.shape, sep='')\n",
    "    print('Writing features to a csv file\\n')\n",
    "    ft.to_csv(experiment + 'Features.csv', )\n",
    "    return ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainTestData (features, test_ratio, k_fold, perfInd):\n",
    "    X_train, X_test, y_train, y_test = createTrainingAndTestDatasets(features, test_ratio)\n",
    "    results = pd.DataFrame(columns = perfInd)\n",
    "    kf = KFold(n_splits = k_fold, shuffle = True)\n",
    "    return X_train, X_test, y_train, y_test, results, kf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Experiment (df, channels, sample_rate, time_window, test_ratio, pca_tolerance, undersampling_method, undersampling_rate, undersampling_neighbors, oversampling_method, oversampling_neighbors, k_fold, epochs, batch, dropout_percentage, loss_function, metric, step, perfInd, experiment):\n",
    "    if experiment.upper() not in ['FULL', 'AVERAGE', 'LEFTRIGHT']:\n",
    "        print('No such experiment:', experiment)\n",
    "        return\n",
    "    else:\n",
    "        print ('Executing Experiment', experiment)\n",
    "    ft = featureExtraction (df, sample_rate, step, pca_tolerance, undersampling_method, undersampling_rate, undersampling_neighbors, oversampling_method, oversampling_neighbors, experiment)\n",
    "    X_train, X_test, y_train, y_test, results, kf = TrainTestData (ft, test_ratio, k_fold, perfInd)\n",
    "    CompleteSVM(X_train, X_test, y_train, y_test, results, ft, kf, perfInd)\n",
    "    CompleteKNN(X_train, X_test, y_train, y_test, results, experiment, ft, kf, perfInd)\n",
    "    CompleteNB(X_train, X_test, y_train, y_test, results, ft, kf, perfInd)\n",
    "    CompleteDT(X_train, X_test, y_train, y_test, results, ft, kf, experiment, perfInd)\n",
    "    CompleteRF(X_train, X_test, y_train, y_test, results, experiment, ft, kf, perfInd)\n",
    "    CompleteLDA(X_train, X_test, y_train, y_test, results, ft, kf, perfInd)\n",
    "    CompleteLR(X_train, X_test, y_train, y_test, results, experiment, ft, kf, perfInd)\n",
    "    if experiment.upper() == 'AVERAGE':\n",
    "        lstm_units = 32\n",
    "        dense_units = 8\n",
    "    elif experiment.upper() == 'LEFTRIGHT':\n",
    "        lstm_units = 64\n",
    "        dense_units = 16\n",
    "    else:\n",
    "        lstm_units = 128\n",
    "        dense_units = 32  \n",
    "    CompleteLSTM(X_train, X_test, y_train, y_test, results, ft, kf, perfInd, epochs, batch, lstm_units, dense_units, dropout_percentage, loss_function, metric)\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

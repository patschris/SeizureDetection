{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import tensorflow as tf\n",
    "from sklearn import model_selection, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.ImportExportData import exportDataframeToCSV,importCsvToDataframe\n",
    "from ipynb.fs.full.EdfManipulation import read_and_store_data\n",
    "from ipynb.fs.full.ClassificationPerformanceIndexes import classificationPerformanceIndexes\n",
    "from ipynb.fs.full.FeatureClassificationMethods import *\n",
    "from ipynb.fs.full.FeatureComputation import leftRightHemisphericChannels, featureExtraction\n",
    "from ipynb.fs.full.FeatureNormalization import featureNormalization\n",
    "from ipynb.fs.full.FeatureSelection import dimentionalityReduction\n",
    "from ipynb.fs.full.DatasetBalancing import oversamplingSMOTE\n",
    "from ipynb.fs.full.SplitDataset import createTrainingAndTestDatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = config['DATASET'].getint('channels')\n",
    "readEdf = config['DATASET'].getboolean('readEdf')\n",
    "csvFile = config['DATASET'].get('csvFile')\n",
    "dataset = config['DATASET'].get('dataset')\n",
    "sample_rate = config['DATASET'].getint('sample_rate')\n",
    "time_window = config['DATASET'].getint('time_window')\n",
    "test_ratio = config['TRAINING'].getfloat('test_ratio')\n",
    "pca_tolerance = config['PCA'].getfloat('pca_tolerance')\n",
    "smote_neighbors = config['SMOTE'].getint('smote_neighbors')\n",
    "k_fold = config['CLASSIFICATION'].getint('k_fold')\n",
    "knn_neighbors = config['CLASSIFICATION'].getint('knn_neighbors')\n",
    "rf_estimators = config['CLASSIFICATION'].getint('rf_estimators')\n",
    "max_iter = config['LOGISTIC'].getint('max_iter')\n",
    "dropout = config['LSTM'].getfloat('dropout_percentage')\n",
    "loss_function = config['LSTM'].get('loss_function')\n",
    "epochs = config['LSTM'].getint('epochs')\n",
    "lstm_units = config['LSTM'].getint('lstm_units')\n",
    "dense1_units = config['LSTM'].getint('dense_layer1_units')\n",
    "dense2_units = config['LSTM'].getint('dense_layer2_units')\n",
    "batch = config['LSTM'].getint('batch')\n",
    "step = time_window * sample_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seazure Detection Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if readEdf:\n",
    "    df = read_and_store_data(dataset, sample_rate, channels)\n",
    "    df = leftRightHemisphericChannels(df)\n",
    "    features = pd.DataFrame(featureExtraction (df, sample_rate, step))\n",
    "    del df\n",
    "    features = featureNormalization(features)\n",
    "    reduced_features = dimentionalityReduction(features, pca_tolerance)\n",
    "    del features\n",
    "    smote_features = utils.shuffle(oversamplingSMOTE(reduced_features.drop('seizure', axis = 1), reduced_features['seizure'], smote_neighbors))\n",
    "    smote_features.reset_index(drop = True, inplace = True)\n",
    "    del reduced_features\n",
    "else :\n",
    "    smote_features = importCsvToDataframe(csvFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dat, test_dat, train_ind, test_ind = createTrainingAndTestDatasets(smote_features, test_ratio)\n",
    "perfInd = ['Accuracy', 'Sensitivity', 'Specificity', 'Precision', 'F1 Score', 'MCC', 'Kappa']\n",
    "results = pd.DataFrame(columns=perfInd)\n",
    "kf = model_selection.KFold(n_splits = k_fold, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM(train_dat, train_ind, test_dat, test_ind, results)\n",
    "SVM_Kfold(smote_features, kf, perfInd, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN(train_dat, train_ind, test_dat, test_ind, knn_neighbors, results)\n",
    "KNN_Kfold(smote_features, knn_neighbors, kf, perfInd, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayes(train_dat, train_ind, test_dat, test_ind, results)\n",
    "NaiveBayes_Kfold(smote_features, kf, perfInd, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTrees(train_dat, train_ind, test_dat, test_ind, results)\n",
    "DecisionTrees_Kfold(smote_features, kf, perfInd, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest(train_dat, train_ind, test_dat, test_ind, rf_estimators, results)\n",
    "RandomForest_Kfold(smote_features, rf_estimators, kf, perfInd, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA(train_dat, train_ind, test_dat, test_ind, results)\n",
    "LDA_Kfold(smote_features, kf, perfInd, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression(train_dat, train_ind, test_dat, test_ind, results, max_iter)\n",
    "LogisticRegression_Kfold(smote_features, kf, perfInd, results, max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reshape train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(train_dat.values, (train_dat.shape[0], 1, train_dat.shape[1]))\n",
    "y_train = train_ind.values.astype(int)\n",
    "X_test = np.reshape(test_dat.values, (test_dat.shape[0], 1, test_dat.shape[1]))\n",
    "y_test = test_ind.values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create LSTM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model1 = Lstm1Model(lstm_units, dense1_units, dense2_units, dropout, epochs, loss_function)\n",
    "lstm_model2 = Lstm2Model(lstm_units, dense1_units, dense2_units, dropout, epochs, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_method (lstm_model1, batch, epochs, X_train, y_train, X_test, y_test, results, 'LSTM1')\n",
    "LSTM_method_Kfold (smote_features, kf, perfInd, lstm_model1, batch, epochs, results, 'LSTM1')\n",
    "LSTM_method (lstm_model2, batch, epochs, X_train, y_train, X_test, y_test, results, 'LSTM2')\n",
    "LSTM_method_Kfold (smote_features, kf, perfInd, lstm_model2, batch, epochs, results, 'LSTM2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 377,
   "position": {
    "height": "287px",
    "left": "1528px",
    "right": "20px",
    "top": "114px",
    "width": "376px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
